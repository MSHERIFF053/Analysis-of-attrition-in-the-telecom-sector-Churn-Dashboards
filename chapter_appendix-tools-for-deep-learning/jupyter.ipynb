{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import json\n",
        "import time\n",
        "from google.colab import files  # For uploading files in Colab\n",
        "import http.client\n",
        "\n",
        "# Function to check if a website is working properly\n",
        "def is_website_working(url):\n",
        "    try:\n",
        "        # Send a GET request to the website\n",
        "        response = requests.get(url, timeout=10)\n",
        "\n",
        "        # Check if the response status code is 404 (not found)\n",
        "        if response.status_code == 404:\n",
        "            print(f\"Website {url} is not found (404).\")\n",
        "            return False\n",
        "\n",
        "        # Check if the page contains a CAPTCHA (e.g., by looking for \"captcha\" in the content)\n",
        "        if \"captcha\" in response.text.lower():\n",
        "            print(f\"Website {url} is asking for CAPTCHA.\")\n",
        "            return False\n",
        "\n",
        "        # Check if the status code is 200 (OK)\n",
        "        if response.status_code == 200:\n",
        "            return True\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error accessing {url}: {e}\")\n",
        "\n",
        "    return False\n",
        "\n",
        "# Upload the Excel file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load the city, state, and country data from the uploaded Excel file\n",
        "excel_filename = list(uploaded.keys())[0]  # This assumes you upload one file\n",
        "sheet_name = \"Sheet1\"  # Change this if your sheet has a different name\n",
        "\n",
        "# Read the city, state, and country data from the Excel file\n",
        "cities_df = pd.read_excel(excel_filename, sheet_name=sheet_name)\n",
        "\n",
        "# Get the current date and time for the output file name\n",
        "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "csv_filename = f\"/content/result{current_time}.xlsx\"  # The output file name will be resultYYYYMMDD_HHMMSS.xlsx\n",
        "\n",
        "# Store previous yoga centers to check for duplicates across rows (tracking by placeId)\n",
        "previous_centers = {}\n",
        "\n",
        "# Create an Excel writer to write the results into an Excel file\n",
        "with pd.ExcelWriter(csv_filename, engine='openpyxl') as writer:  # Change the engine to 'openpyxl'\n",
        "    # Create a list to store all the rows for final writing to Excel\n",
        "    all_rows = []\n",
        "\n",
        "    # Write headers for city, state, country, and up to 20 yoga centers\n",
        "    header = [\"City\", \"State\", \"Country\"]\n",
        "    for i in range(1, 21):  # Adjusted for 20 centers\n",
        "        header.extend([f\"center{i}name\", f\"center{i}website\", f\"center{i}review\"])\n",
        "\n",
        "    # Iterate through each row in the Excel data\n",
        "    for index, row in cities_df.iterrows():\n",
        "        total_rows = len(cities_df)  # Total number of rows in the sheet\n",
        "        print(f\"Processing row {index + 1}/{total_rows}...\")  # Show the current row number and total rows\n",
        "\n",
        "        city = row['city']\n",
        "        state = row['state']\n",
        "        country = row['country']\n",
        "\n",
        "        # Construct the search query for yoga studios\n",
        "        query = f\"yoga in {city}, {state}, {country}\"\n",
        "\n",
        "        # Initialize row data with city, state, country\n",
        "        row_data = [city, state, country]\n",
        "\n",
        "        # Keep track of seen center IDs to avoid duplicates in this row\n",
        "        seen_center_ids = set()\n",
        "\n",
        "        # Try the first search (city, state, country)\n",
        "        response_json = None\n",
        "        try:\n",
        "            # API Connection\n",
        "            conn = http.client.HTTPSConnection(\"google.serper.dev\")\n",
        "            payload = json.dumps({\n",
        "                \"q\": query,\n",
        "                \"gl\": \"AR\"  # Modify location as needed\n",
        "            })\n",
        "            headers = {\n",
        "                'X-API-KEY': 'abfe315b7f9e4392041a4aff90c4ccd4ebcdfad4',  # Use your valid API key\n",
        "                'Content-Type': 'application/json'\n",
        "            }\n",
        "\n",
        "            # Send request\n",
        "            conn.request(\"POST\", \"/maps\", payload, headers)\n",
        "            res = conn.getresponse()\n",
        "            data = res.read()\n",
        "            response_json = json.loads(data)\n",
        "\n",
        "            if 'statusCode' in response_json and response_json['statusCode'] == 403:\n",
        "                print(f\"Response from first search for {query}: {response_json}\")\n",
        "                raise Exception(f\"Unauthorized access for {query}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in first search for {query}: {e}\")\n",
        "\n",
        "        # If no results from the first search, try searching just by country\n",
        "        if response_json is None or 'places' not in response_json or len(response_json['places']) == 0:\n",
        "            print(f\"Searching for yoga in {country}...\")\n",
        "            query = f\"yoga in {country}\"\n",
        "            try:\n",
        "                # Send request for country search\n",
        "                conn.request(\"POST\", \"/maps\", payload, headers)\n",
        "                res = conn.getresponse()\n",
        "                data = res.read()\n",
        "                response_json = json.loads(data)\n",
        "\n",
        "                if 'statusCode' in response_json and response_json['statusCode'] == 403:\n",
        "                    print(f\"Response from second search for {query}: {response_json}\")\n",
        "                    raise Exception(f\"Unauthorized access for {query}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in second search for {query}: {e}\")\n",
        "\n",
        "        # If still no valid response, continue to next row\n",
        "        if 'places' not in response_json or len(response_json['places']) == 0:\n",
        "            print(f\"No yoga centers found for {city}, {state}, {country}\")\n",
        "            row_data.extend([\"N/A\", \"N/A\", \"N/A\"] * 20)  # Fill with \"N/A\" if no results found\n",
        "            all_rows.append(row_data)\n",
        "            continue\n",
        "\n",
        "        # Extract the details for each yoga studio in the response\n",
        "        centers_found = 0\n",
        "        print(f\"Searching for centers in {city}, {state}, {country}...\")\n",
        "        for place in response_json.get(\"places\", []):\n",
        "            name = place.get(\"title\", \"N/A\")\n",
        "            website = place.get(\"website\", \"N/A\")\n",
        "            place_id = place.get(\"placeId\", None)\n",
        "\n",
        "            # Skip the place if it already exists in the same row (check by placeId)\n",
        "            if place_id and place_id in seen_center_ids:\n",
        "                continue\n",
        "            # Add to seen centers set to track uniqueness in this row and globally across previous rows\n",
        "            if place_id:\n",
        "                seen_center_ids.add(place_id)\n",
        "                previous_centers[place_id] = {\"name\": name, \"website\": website, \"review_url\": f\"https://www.google.com/maps/place/?q=place_id:{place_id}\"}\n",
        "\n",
        "            # Only check the website if it's valid\n",
        "            if website != \"N/A\" and is_website_working(website):\n",
        "                # Construct the review URL using place_id if available\n",
        "                review_url = f\"https://www.google.com/maps/place/?q=place_id:{place_id}\" if place_id else \"N/A\"\n",
        "\n",
        "                # Add center details if the website is working\n",
        "                print(f\"Found working website: {name}, {website}, {review_url}\")\n",
        "                row_data.extend([name, website, review_url])\n",
        "                centers_found += 1\n",
        "\n",
        "            # Stop adding centers after the first 20 valid ones\n",
        "            if centers_found >= 20:\n",
        "                break\n",
        "\n",
        "        # Fill in the missing center details with \"N/A\" if there are less than 20 valid centers\n",
        "        while centers_found < 20:\n",
        "            row_data.extend([\"N/A\", \"N/A\", \"N/A\"])\n",
        "            centers_found += 1\n",
        "\n",
        "        # Append row data to the list of all rows\n",
        "        all_rows.append(row_data)\n",
        "\n",
        "        # Be respectful of rate limits by pausing between requests if needed\n",
        "        time.sleep(1)  # Adjust sleep time based on API rate limits\n",
        "\n",
        "# Write all the data into the Excel file\n",
        "df = pd.DataFrame(all_rows, columns=header)\n",
        "df.to_excel(writer, index=False, sheet_name='Yoga Centers')\n",
        "\n",
        "print(f\"Scraped results from {len(cities_df)} cities and saved to {csv_filename}\")\n",
        "\n",
        "# Use the following command to download the file to your local machine\n",
        "files.download(csv_filename)\n"
      ],
      "metadata": {
        "id": "6tgvjs-GCLCL",
        "outputId": "b5def0da-28ab-49e7-9605-cb2f815c42e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6tgvjs-GCLCL",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped results from 497 cities and saved to /content/result20250219_163144.xlsx\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}